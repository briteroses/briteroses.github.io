---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: left
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I'm a recent graduate from MIT with Bachelor's degrees in Math & CS as well as a Master's in CS. I'm broadly interested in understanding failure modes and weaknesses in frontier AI systems in order to robustify real-world deployment of AI systems.

At MIT, I was fortunate to conduct research on adversarial robustness of deep learning models, advised by [Hadi Salman](https://hadisalman.com/) and [Aleksander MÄ…dry](https://madry.mit.edu/). I was also a teaching assistant for MIT's flagship graduate-level machine learning class (6.867, now [6.7900](https://gradml.mit.edu/)) and for the statistical data analysis class (6.3720/3722). In past internships/research experiences, I've worked on causal intervention methods for mech interp @ Redwood Research; researched ~quantitatively~ at JPMorgan Chase and WorldQuant; and investigated differential-geometric properties of black hole formation in general relativity with [Marcus Khuri](https://www.math.stonybrook.edu/cards/khurimarcus.html) at Stony Brook University. I'm currently at [Haize Labs](https://haizelabs.com/) doing research and engineering for red-teaming, automated evals, and adversarial robustness; so far, I've led Haize's red-teaming contract with OpenAI for their o1 model release, worked on our redteaming research contract with Anthropic, and have done exciting research across jailbreaking and content moderation systems.