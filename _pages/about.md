---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: left
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I'm a recent graduate from MIT with Bachelor's degrees in Math & CS as well as a Master's in CS. I'm broadly interested in machine learning methods and evaluations that may engender more equitable and harm-reducing outcomes for frontier AI systems.

At MIT, I was fortunate to conduct research on adversarial robustness of deep learning models, advised by [Hadi Salman](https://hadisalman.com/) and [Aleksander MÄ…dry](https://madry.mit.edu/). I was also a teaching assistant for MIT's flagship graduate-level machine learning class (6.867, now [6.7900](https://gradml.mit.edu/)) and for the statistical data analysis class (6.3720/3722). Before undergrad, I researched black hole formation in general relativity with [Marcus Khuri](https://www.math.stonybrook.edu/cards/khurimarcus.html) at Stony Brook University. Since graduation, I've briefly worked on autonomous driving and perception at [Matic](https://maticrobots.com/), and conducted independent research in mechanistic interpretability with a friend that I presented at the NeurIPS ATTRIB workshop. I'm currently "haizing" language models with [Haize Labs](https://haizelabs.com/), working on a few exciting research directions to better understand the vulnerabilities of current safety measures in frontier models.

I'm actively recruiting; if you have a job opportunity that you think may be a strong fit, feel free to reach out!